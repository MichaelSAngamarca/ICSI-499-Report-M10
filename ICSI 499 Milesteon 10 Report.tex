\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{tikz}

\begin{document}

% ----------------- TITLE PAGE -----------------
\begin{titlepage}
    \thispagestyle{empty}
    \centering
    \vspace*{2cm}

    {\large ICSI 499 Capstone Project Report \par}
    \vspace{1.5cm}

    {\Huge \textbf{TalkAssist} \par}
    \vspace{2cm}

 {\large \textit{Michael Angamarca} \par}
 {\large \textit{Kyle Batchelor} \par}

 {\large \textit{Ayan Cooper} \par}
 {\large \textit{Isaac Jean Gardy Mardy} \par}
    \vspace{0.3cm}
    {\large \textit{Team 5} \par}
 \vspace{0.3cm}

    College of Nanotechnology, Science, and Engineering \\
    University at Albany, SUNY

    \vspace{2cm}

    {\large \textit{Project Sponsor:} \par}
    \vspace{0.5cm}

    Dr. Pradeep Atrey \\
    Athulya Mathew \\
    Department of Computer Science \\
    College of Nanotechnology, Science, Engineering \\
    University at Albany \\
    UAB 421, 1215 Western Avenue, Albany, NY 12222

    \vspace{3cm}

    {\large \today}
\end{titlepage}


% ----------------- FRONT MATTER -----------------
\pagenumbering{roman}

% ----------------- ACKNOWLEDGMENTS -----------------
\newpage
\thispagestyle{plain}
\begin{center}
    \Large \textbf{Acknowledgments}
\end{center}

\vspace{1cm}

\noindent
Team 5 would like to extend our heartfelt appreciation to Professor Pradeep Atrey and Athuyla Matthew for their unwavering support and encouragement. Their guidance throughout the development of TalkAssist inspired us, challenged us, and enabled us to transform our vision into a working product.

\vspace{0.5cm}

\noindent
The motivation behind Talk Assist was to develop a tool that people with life-altering visual disabilities might utilize to live their lives on an equal footing with people without them. We aim to sustain this purpose and produce a product that satisfies these great expectations placed upon us by our sponsors and the University at Albany.


% ----------------- ABSTRACT -----------------
\newpage
\thispagestyle{plain}
\begin{center}
    \Large \textbf{Abstract}
\end{center}

\vspace{1cm}

\noindent
Talk Assist is an artificial intelligent voice assistant designed for individuals with visual disabilities. The project's objective is to create, test, and assess an AI driven voice assistant that supports visually impaired users in managing daily life. Talk Assist includes two unique modes that allow users to dynamically transition based on Internet connectivity. Users can request online searches, weather, time, date information, and reminders in Online Mode. In Offline Mode, Talk Assist preserves the same weather, time, date, and reminder functionality, while also offering a calculation utility for basic computations. Talk Assist aims to simplify daily tasks for visually impaired users without the need for expensive or inaccessible healthcare technologies.

\newpage
\thispagestyle{plain}
\tableofcontents
\newpage


% ----------------- PROBLEM ANALYSIS -----------------
\newpage
\pagenumbering{arabic}

\section{Problem Analysis}

\subsection{Project Statement}
Individuals with visual impairments often face significant challenges when interacting with everyday technology. Tasks such as reading screens, managing schedules, accessing online information, or performing basic device operations can require specialized tools or expensive accessibility technologies. Many existing solutions lack adaptability, rely heavily on constant internet connectivity, or are too complex for seamless daily use.

TalkAssist aims to address these challenges by providing an intuitive, AI powered voice assistant specifically designed for users with limited or no vision. The goal of this project is to design, implement, and evaluate a system that supports both online and offline functionality, delivers accurate voice feedback, and simplifies daily tasks through natural speech interaction. By integrating reliable recognition, high quality text-to-speech components, and an interface tailored for accessibility, TalkAssist seeks to make digital interaction more equitable and practical for visually impaired individuals.

\subsection{What are Existing Solutions?}
Several solutions exist in the accessibility and voice-assistant space, such as Apple’s VoiceOver, Google Assistant, and Amazon Alexa. While powerful, these tools are developed for broad consumer audiences rather than tailored explicitly for visually impaired users. As a result, they often require complex setups, consistent cloud connectivity, or rely on visual interfaces not optimized for non-sighted users.

Some standalone accessibility devices provide improved usability such as scre, but they can be costly and inaccessible to many. These systems also frequently depend on external hardware or lack offline capability, making them unreliable in environments with unstable internet connections.

Additionally, visually impaired users report issues such as inconsistent voice feedback, poor environmental adaptability, and difficulty performing basic tasks when offline. Users often struggle to transition smoothly between connected and disconnected settings, resulting in a fragmented user experience.

\subsection{Our Solution}
TalkAssist provides a unified, accessibility focused platform designed to meet the needs of visually impaired users in both online and offline contexts. Our system introduces the following key features:

\begin{itemize}
    \item \textbf{Dual-Mode Functionality:} Users can operate TalkAssist in Online Mode for tasks such as web searches, weather updates, and general questions, while Offline Mode preserves essential functions like time, date, reminders, and basic calculations.
    
    \item \textbf{Accessible Voice Interaction:} The system is designed around natural speech input and clear spoken output, minimizing dependence on visual cues or screen navigation.
    
    \item \textbf{Task Management and Reminders:} Users can create, update, and manage reminders through simple voice commands in both online and offline modes, supporting daily independence.
    
    \item \textbf{Lightweight and Low-Cost Design:} Unlike expensive commercial assistive devices, TalkAssist runs on standard consumer hardware, making it affordable and widely accessible.
\end{itemize}

Together, these features create a streamlined accessibility tool that empowers visually impaired individuals to manage tasks, retrieve information, and interact with technology more independently and confidently.

\subsection{Overview of Report}
The remainder of this report is structured as follows:

\begin{itemize}
    \item \textbf{Section 2} describes TalkAssist's design and capabilities, including its API architecture, applications, and implementation techniques.
    \item \textbf{Section 3} describes the testing procedure, system performance analysis, and research design.
    \item \textbf{Section 4} addresses security, legal, and ethical issues like user privacy, data security, and dependency on third-party APIs.
    \item \textbf{Section 5} presents a breakdown of the roles and contributions of the team.
    \item \textbf{Section 6} highlights potential future enhancements and growth opportunities for Talk Assist before concluding the paper.
\end{itemize}

%SECTION 2 

\section{Proposed System/Application/Study}

\subsection{Overview}

TalkAssist is designed to support individuals across a broad spectrum of visual impairments. To effectively serve this user group, the system is built around three core requirements: a fully non-visual interface, highly accurate text-to-speech and natural language processing capabilities, and complete hands-free operation through voice interaction. In this section, we provide an overview of our project requirements, describe our system architecture, and walk through the major components of our implementation. We also highlight the core computer science and software engineering principles applied throughout the project including time complexity considerations, natural language processing techniques, API integration, and system design techniques.

\subsection{Project Requirements}

\subsubsection{User Classes}
There are two distinct user classes. Application Users are individuals who interact directly with TalkAssist. This group includes users with visual impairments who rely on fully voice-driven, non visual interaction. Their primary goal is to communicate with the chatbot, receive accurate spoken responses, and operate the system entirely hands-free. Event Management Users rely on TalkAssist to manage time based tasks such as reminders, alerts, and scheduled notifications. To stay organized without requiring visual involvement, these users rely on precise voice-controlled scheduling and clear audio confirmations.

\subsubsection{Functional Requirements}
\begin{itemize}
\item\textbf{Front End GUI:} Talk Assist requires a simple and clear front-end GUI that is able to transcribe conversations and also indicate when either offline or online mode is currently running. The GUI must also contain a reminders page that clearly shows each active reminder and is able to differentiate between active and inactive reminders.

\item\textbf{Online Mode:} Talk Assist requires an online mode that is able to perform commands such as telling the time, weather, date, and setting reminders. It should also be able to search the web for answers to questions asked by the user. We require this online connection as Talk Assist’s online mode has many more capabilities and is meant for at-home use.

\item\textbf{Offline Mode:} Talk Assist requires a lightweight offline mode that is able to perform similar but more basic tasks than its online mode. Offline mode should still be able to tell time, weather, date, and set reminders. There are no web search capabilities, but this is offset by a basic calculation tool that allows offline mode to perform operations requested by the user. Offline mode is lightweight due to this mode being intended for out-of-home use, such as while walking or grocery shopping.

\item\textbf{Wake Up Word \& Hot Key:} Due to Talk Assist’s hands-off approach to operation, we require wake-up word and hotkey capabilities. The wake-up word is meant to activate the program and start a conversation once detected, allowing the user to avoid restarting the program to begin a new conversation. The hotkey is required to allow the user to launch the application and begin microphone recording for wake-up word activation, enabling them to avoid navigating a screen and streamlining the application launch process.
\end{itemize}

\subsubsection{Non-Functional Requirements}
\begin{itemize}
\item\textbf{Accessibility:}The system must be fully usable without visual navigation (screen-reader friendly, voice-first interaction)
\item\textbf{Usability:}The chatbot must have a simple, natural, and intuitive voice-based interaction flow. Responses should be clear, concise, and easy to understand for users with varying levels of technical skill
\item\textbf{Scalability:}App should support integration with additional features ( calendars, weather APIs, reminders) without major redesign
\item\textbf{Portability:}Should scale to run on multiple platforms in future (desktop and mobile) with minimal configuration
\end{itemize}
\subsubsection{Operating Requirements}
In terms of operating reqiurements, Talk Assist only needs a simple laptop with any windows based operating system to run on. Windows gives us the ability to access the users microphone and keyboard input without limitation like in other operating systems. 
\subsubsection{Design and Implementation Constraint}
Future developers ought to address a number of design constraints that have hindered conversation assistance. Build limitations on operating systems such as MacOS are one of these issues. As previously stated, MacOS unfortunately prevents the usage of some libraries, including keyboard and microphone access libraries, therefore we can only build for Windows. The dependence on third-party APIs is another problem. We are unable to control rate limitation because we use a lot of free and open source APIs. Certain talk-assist tools, such time and weather information, are prohibited from use while rate restriction takes place because the corresponding API restricts our use for a while. 

\subsection{Solution Architecture}
Three separate components make up Talk Assist's architecture solution. We are using the Eleven Labs API in its Online Mode, which generates a conversational agent. When our software runs, it calls ElevenLabs and gives the agent the associated ID that we have generated. ElevenLabs enables us to program agent tools, such as weather, time, and reminder tools, which are subsequently called by the agent when necessary. 
\newpage
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{TalkAssistOnline.png}
    \caption{
        TalkAssist system architecture.  
        Online mode uses the ElevenLabs API for agent communication. What a normal average use case of Talk Assist looks like when running in online mode.
    }
    \label{fig:architecture}
\end{figure}

Offline mode in TalkAssist ensures accessibility when internet connectivity is unavailable.
The system continuously checks network availability and automatically switches to offline
mode upon failure, returning to online mode once connectivity is restored. In offline mode,
all processing occurs locally using a Whisper speech to text model and offline text to speech
libraries such as pyttsx3. Core features including time and date queries, reminders, and basic
calculations remain available, with reminders stored locally to preserve privacy and
reliability.
\begin{figure}[h!]
\centering
\includegraphics[width=0.95\textwidth]{TalkAssist_DFD.png}
\caption{Level-1 Data Flow Diagram for TalkAssist}
\end{figure}

\newpage
Lastly, we put the connection based handling method into operation. This method uses built in Python tools to send a lightweight request to a Google.com instance on a regular basis to a known, dependable endpoint. To guarantee dynamic and ongoing network state monitoring, this check is carried out every five seconds.The system verifies that an internet connection is available and automatically enters online mode if a successful response is received. In contrast, the system enters offline mode if the request is unsuccessful, assuming that connectivity has been lost. Throughout the program's execution time, this method enables it to smoothly adjust anytime the network connection is lost or restored, even while the application is running.
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{ConnectionCheck.png}
    \caption{
        TalkAssist connection detection architecture is a process that runs on every program operation and doesn't stop until the application ends. essential to the online and offline modes' integration. 
    }
    \label{fig:architecture}
\end{figure}

\subsection{System Implementation}
To guarantee seamless collaboration and maintainability, our team operated in a single, unified development environment. Visual Studio Code (VSCode), a strong yet lightweight IDE that works well with Python development workflows, was the main tool we used. We set up a specific Python virtual environment for the project in order to maintain dependencies separate and organized. Git was used for version control, enabling the team as a whole to manage branches, keep the main branch secure and current with each commit, and track changes. In addition to the core technologies already discussed such as ElevenLabs and OpenAI Whisper—we incorporated several other important libraries and tools to support more advanced functionality. Some of the most notable include PyAudio, Pyttsx3, APScheduler, and PyInput. These tools played a important role in enabling key system features, especially the offline mode, which required local audio processing and event handling without relying on external too many external APIs.

\subsection{Use of Computer Science Theory and Software Development Fundamentals}

Throughout the development of TalkAssist, our team relied heavily on core software engineering practices and foundational computer science principles to ensure that the system was reliable, maintainable, and capable of supporting both online and offline functionality. The following subsections highlight the major theoretical concepts and development fundamentals used throughout the project.

\subsubsection{Use of Computer Science Theory}

\begin{itemize}
\item\textbf{Natural Language Processing (NLP)}
TalkAssist relies on NLP concepts such as intent recognition, keyword extraction, and speech to text tokenization. Even though we used external models such as Whisper, we applied NLP logic internally for example, distinguishing between “times” (multiplication) and “time” (clock queries), or mapping spoken phrases to internal commands.
\item\textbf{Run Time Complexity Optimization}
To make sure TalkAssist stayed fast and responsive, we applied basic runtime and time complexity principles during development. For reminders, we kept storage simple by using a small JSON file and only searching through what was necessary, reducing extra file reading. Our wake word detection and internet connection checks were designed to run in constant time so they would not slow down the rest of the program. In offline mode, we used lightweight text[matching methods instead of heavier processing to keep responses quick. These choices helped the system run smoothly and efficiently, even on regular laptops without high processing power.
\end{itemize}

\subsubsection{Use of Software Development Fundementals}
\begin{itemize}
\item\textbf{API Integration and Interface Handling:}  
Integrating ElevenLabs, Whisper, and weather/time APIs required careful schema handling, error checking, and adherence to rate limits. Clear input/output interfaces were designed so components could interact without exposing internal implementation details.
\item\textbf{System Design}
TalkAssist was divided into functional components, including the GUI, connection monitoring subsystem, reminders, text to speech, speech recognition, and API handlers. It makes debugging easier, decreased overlap in work, and let team members assume responsibility for particular parts.
\end{itemize}

\section{Experimental Design and Testing}

This section presents the experimental methodology used to evaluate TalkAssist across its online mode, offline mode, voice driven functionality, and graphical user interface (GUI) components. The goal of these experiments is twofold: \textbf{verification} – confirming that TalkAssist’s implemented features behave correctly – and \textbf{validation} – determining whether the system adequately addresses the needs of visually impaired users who rely on fully voice operated systems. Tests were conducted by multiple team members, each focusing on different subsystems: online speech recognition reliability, offline speech to text and reminder management, mathematical query handling, and frontend accessibility. Collectively, these experiments provided a comprehensive assessment of TalkAssist’s usability, accuracy, and robustness in realistic user conditions.



We designed five experiments, numbered by subsystem:

\begin{enumerate}
    \item Online Voice Only Navigation Test
    \item Online Speech Recognition Across Recording Environments
    \item Accuracy of Mathematical Query Parsing
    \item Offline Speech Recognition and Offline Reminder Management
    \item Frontend Recording Indicator Behavior (GUI Test)
\end{enumerate}

Each experiment was conducted to target different risk areas, including voice accuracy, robustness under noise, correct command interpretation, deterministic behavior offline, and the accessibility of the user interface for non visual users. Because TalkAssist is intended for visually impaired users, tests emphasized hands free usage, speech only interaction, and clarity of system feedback.

\subsubsection{Experiment 1: Online Voice Only Navigation Test}

\textbf{Objective:} To determine whether TalkAssist’s online version can be fully navigated without visual access to the GUI.

\textbf{Setup:} The tester shut their eyes or used a pillowcase to simulate blindness. The online version of TalkAssist ran on a Windows laptop in a quiet room. Only voice commands were used to navigate between features such as time queries, reminders, and basic Q\&A responses.

\textbf{Environment \& Tools:}
\begin{itemize}
    \item Chrome browser running TalkAssist web interface
    \item Built in laptop microphone
    \item No keyboard or mouse input permitted
\end{itemize}

\textbf{Purpose:} To validate whether TalkAssist meets its accessibility goal: functioning as a screen reader free, voice only assistant.

\subsubsection{Experiment 2: Online Speech Recognition Across Varying Recording Environments}

\textbf{Objective:} To test the reliability of online speech recognition under changes in microphone quality and ambient noise.

\textbf{Setup:} Several recording environments were tested:

\begin{itemize}
    \item Quiet bedroom
    \item Medium noise room (TV and conversation noise)
    \item Crowded living room
\end{itemize}

Multiple microphones were evaluated, including laptop microphones and USB headsets.

\textbf{Purpose:} To determine if TalkAssist maintains voice recognition accuracy across common, real world usage environments.

\subsubsection{Experiment 3: Mathematical Query Parsing}

\textbf{Objective:} To test the chatbot’s ability to correctly handle mathematical computations using natural language.

\textbf{Setup:} A series of spoken math prompts were used, including:

\begin{itemize}
    \item “What is 5 plus 7?”
    \item “Calculate the sum of 5 and 4.”
    \item Phrases containing “times” to test disambiguation from time queries
\end{itemize}

\textbf{Purpose:} To validate the correctness of the math parser and ensure disambiguation logic prevents false triggers.

\subsubsection{Experiment 4: Offline Speech Recognition and Reminder Management}

\textbf{Objective:} To evaluate TalkAssist’s offline functionality, which is critical when internet access is unavailable.

\textbf{Setup:}

\textbf{Hardware:} Windows 11 laptop with USB microphone  
\textbf{Software:} Whisper base model (70M parameters), Python 3.10 virtual environment  

\textbf{Environments:}
\begin{itemize}
    \item Quiet room
    \item Medium background noise (open window, distant voices)
\end{itemize}

Tests included:
\begin{itemize}
    \item Speech to text accuracy
    \item Local reminder creation, storage, and retrieval using \texttt{reminders.json}
    \item Offline text-to-speech playback
\end{itemize}

\textbf{Purpose:} To ensure the assistant remains usable when connectivity is poor or unavailable.

\subsubsection{Experiment 5: GUI Recording-Indicator Behavior}

\textbf{Objective:} To test whether the TalkAssist interface correctly indicates when the system is actively listening for user speech.

\textbf{Setup:} The tester issued voice commands while visually monitoring the recording indicator, which should activate only during input capture.

\textbf{Purpose:} To determine whether the indicator switches states correctly and provides reliable feedback.

\textbf{Observed Issue:} The bot continues listening during its own speech, causing the indicator to remain active. This experiment helped isolate whether the issue came from frontend timing, Web Speech API delays, or backend latency.

\subsection{Dataset}

Because TalkAssist relies heavily on natural language input, each experiment generated a dataset of spoken commands and system outputs.

\subsubsection*{Dataset for Experiments 1 \& 2 (Online Mode)}

\begin{itemize}
    \item 2 internal testers simulating visually impaired usage
    \item $\sim$60 navigation and Q\&A commands
    \item 40 environmental speech samples across three noise levels
    \item Tests across 2 microphone types
\end{itemize}

Each dataset included:
\begin{itemize}
    \item STT transcriptions
    \item Intent parser outputs
    \item Success/failure indicators
\end{itemize}

\subsubsection*{Dataset for Experiment 3 (Math Parsing)}

\begin{itemize}
    \item 25 spoken mathematical expressions
    \item Operator-based and phrase based queries
    \item Misinterpretation cases logged
\end{itemize}


The combined datasets provide coverage for accuracy, robustness, and user experience evaluation across TalkAssist’s full set of features.


%Section 4

\section*{4 \quad Legal and Ethical Practices}
\addcontentsline{toc}{section}{4 Legal and Ethical Practices}

\subsection*{4.1 \quad Legal Considerations}
\addcontentsline{toc}{subsection}{4.1 Legal Considerations}

\textbf{Use of Third Party Libraries:}
Only speech to text, text to speech, and API tools with proper open source or permissive licenses (MIT, Apache, etc.) were used to avoid copyright or IP violations.

\textbf{Reminder Data Storage:}
\begin{itemize}
    \item TalkAssist does not store voice recordings.
    \item It does save reminder text (e.g., ``Take medication at 3 PM'') in a local JSON file.
    \item Because this information may be personal or sensitive, all stored data remains on the user's device.
\end{itemize}

\textbf{Privacy and Data Protection:}
Local only storage reduces risks related to major data protection laws (GDPR, state privacy laws). Users are informed that reminder text is stored to ensure transparency.

\textbf{Online Service Compliance:}
When TalkAssist uses online features (e.g., weather, general information), the system abides by the terms and usage limits of each external API.

\textbf{Third-Party API Privacy Concerns (e.g., ElevenLabs):}
\begin{itemize}
    \item ElevenLabs stores all audio sent through its API, including user conversations and generated speech.
    \item The service retains transcription logs and audio logs, meaning TalkAssist cannot fully control or delete user data once it is sent.
    \item This creates privacy concerns, especially when users provide sensitive or personal information through voice interactions.
    \item Users should always be informed whenever an external API provider stores or processes their data.
\end{itemize}

\textbf{Liability Reduction:}
Clear limitations are placed on high  risk tasks, and the assistant avoids giving medical, legal, or dangerous instructions.

\vspace{1em}

\subsection*{4.2 \quad Ethical Considerations}
\addcontentsline{toc}{subsection}{4.2 Ethical Considerations}

\textbf{Protection of Vulnerable Users:}
Designed for individuals with visual impairments, the system avoids misleading, unsafe, or unclear responses.

\textbf{Privacy \& User Consent:}
\begin{itemize}
    \item Reminders may contain private routines or sensitive tasks.
    \item Users are informed that reminders are stored locally and may delete them at any time.
    \item No hidden data collection or cloud storage is used.
\end{itemize}

\textbf{Third-Party API Privacy Concerns (e.g., ElevenLabs):}
\begin{itemize}
    \item ElevenLabs stores all audio sent through its API, including user conversations and generated speech.
    \item The service retains transcription logs and audio logs, meaning TalkAssist cannot fully control or delete user data once it is sent.
    \item This creates privacy concerns, especially when users provide sensitive or personal information through voice interactions.
    \item Users should always be informed whenever an external API provider stores or processes their data.
\end{itemize}

\textbf{Data Minimization:}
Only essential reminder information is saved—nothing more.

\textbf{User Autonomy \& Control:}
Users can freely create, edit, or remove reminders; the assistant never makes decisions without explicit instruction.

\textbf{Transparency of Modes:}
The bot clearly distinguishes between offline processing (fully private) and online processing (which may contact external APIs).

\textbf{Inclusivity and Accessibility:}
Every feature is designed to enhance independence, clarity, and accessibility for visually impaired users.

%Section 5
\section*{5 \quad Effort Sharing}
\addcontentsline{toc}{section}{5 Effort Sharing}
Tasks that were completed together include sponsor meetings over zoom and in person as well as communication within the team GroupMe in order to manage everyones task and completion of said tasks. Below you can find a table and explanation of each persons contribution percentage and explanation

\begin{itemize}
\item\textbf{Michael Angamarca (Team Leader):}
Worked on all online features, with the exception of reminders. Also finished integrating online and offline modes with the front-end, helped redesign the frontend GUI, and finished integrating connection with the online and offline modes. Coordinated all team responsibilities by milestone deadlines and assisting to write Talk Assist documentation (M10 Doc, Slideshows, etc.) 
\item\textbf{Kyle Batchelor: }
Primarily worked on the offline mode. In particular, finishing the offline mode computation functionality. Collaborated with other members to finish a portion of the offline functionality. Helped finish the Talk Assist documentation (M10 Doc, Slideshow, and Milestone Videos).
\item \textbf{Isaac Jean Gardy Mardy:}
Primarily focused on the implementation of offline mode. Completed nearly all offline
functionality and also contributed to the development of the online mode's reminder
features. Collaborated with other team members to integrate the backend with the GUI
and ensure seamless transitions between online and offline modes. Assisted in completing
TalkAssist documentation (M10 Doc, Slideshows, and Milestone Videos).
\item\textbf{Ayan Cooper: }
Primarily worked on creating a GUI for Talk Assist. Soley has created the initial draft of the GUI and contributed to its second iteration and implementation. Collaborated with others to integrate both the front and back ends. Helped finish the Talk Assist documentation (M10 Doc, Slideshows, and Milestone Videos).
\end{itemize}
\begin{table}[h!]
\centering
\caption{Effort Sharing Among Team 5 Members}
\scriptsize
\setlength{\tabcolsep}{1pt}  
\small
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Team size} &
\textbf{Joint efforts} &
\textbf{Michael Angamarca} &
\textbf{Kyle Batchelor} &
\textbf{Isaac Jean Gardy Mardy} &
\textbf{Ayan Cooper} \\
\hline
4 & J (20\%) & I (22\%) & I (15.5\%) & I (22.5\%) & I (20\%) \\
\hline
\end{tabular}

\vspace{2mm}
\footnotesize
J = description of tasks jointly performed (sponsor meetings, team communication, coordination, and documentation) \\
I = description of tasks individually performed (see bullet points above)
\end{table}

%Section 6
\section*{6 \quad Conclusion and Future Work}
\addcontentsline{toc}{section}{6 Conclusion and Future Work}

The development of TalkAssist allowed us to design and implement an accessible
voice driven assistant that supports both online and offline functionality for
visually impaired users. Through this project, we learned how to integrate
speech technologies, manage system modes, and design intuitive interactions that
reduce dependence on visual interfaces. While the current system performs core
tasks reliably, future work includes expanding offline capabilities, improving
natural language understanding, and integrating additional online services such
as calendars and navigation. Long term improvements may also include mobile
platform support and a more advanced wake word system to further enhance
accessibility and user independence.

\end{document}